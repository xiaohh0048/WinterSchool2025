{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四节：进阶版 Transformer 实战\n",
    "\n",
    "前面的章节中我们已经一步步实现了用 PyTorch 自带 Transformer 模块搭建基础的 Transformer 模型，在高能物理分析的分类任务中进行了实战。现在，我们将探索应如何按照高能物理数据的格式制作更好的 Transformer，取得更优越的性能。\n",
    "\n",
    "这将使我们引出 Particle Transformer (ParT, [H. Qu *et al*. ICML 2022](https://arxiv.org/abs/2202.03772))，高能物理领域里目前较成熟的，处理 particle-format data 的 Transformer 结构。它也是2025年之前作喷注鉴别最好的模型。\n",
    "\n",
    "本节分两部分：\n",
    "\n",
    " - 首先，我们指出加入 pairwise particle masses 的妙处（即 ParT 的精髓），并基于上节最后的例子进行修改，实现一个简单版本的ParT。这将主要用作教学案例。\n",
    " - 其次，我们提供一个直接调用 ParT 模型（以及此前更出名的 ParticleNet, ParticleNeXt 模型，都在[这个文件夹内](https://github.com/hqucms/weaver-core/tree/main/weaver/nn/model)）的代码样例。根据此前收集到的建议，这或许对大家后续真正使用这些模型有帮助：希望可以作为一个范本，方便大家进行修改以适配到自己的任务中。\n",
    " <!-- - 在本章的最后，我们加入一个处理 token 数目达到 o(50-100) 的复杂任务，喷注鉴别 (jet tagging)。我们将使用较早的 Top Landscape dataset ([G. Kasieczka *et al*. SciPost Phys. 7, 014 (2019)](https://arxiv.org/abs/1902.09914)) 进行举例，接入上一步制作的 ParticleNet / ParticleNeXt 接口进行训练。这也可以作为一个处理复杂任务的范本，对大家后续使用这些模型有帮助。 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如果在 Google Colab 中使用，请首先运行下面的命令安装相关的python包。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install uproot==4.2.2 pandas==1.3.4 mplhep==0.3.12 weaver-core\n",
    "! pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从 “plain Transformer” 到 Particle Transformer (ParT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们上节已经实现了“平淡”的Transformer：\n",
    "\n",
    " - 把每个物理对象（jet，轻子和MET）当做一个token，让它们在 Transformer block 中利用 attention 机制“相互交流”，传递信息，并通过 FFN 来更新自己的潜空间表示。\n",
    " - 我们在最开始定义了一个专门的可训练的 class token，让他和其它真实的 token 一起交流。最后进行分类时，用它的最后的潜空间向量得到分类的 logits。\n",
    "\n",
    "虽然我们的task都是简单的分类任务，不足以体现出 Transformer 在模型参量增大、数据规模增大时强大的 scaling 能力，但是在工程学实践中，当处理及其复杂的输入变量和分类问题时，用现在的 Transformer 模型还有性能提升的空间。如何继续修改 Transformer 网络的设计，让它更“聪明”？一个工程学经验是，需要认识到我们处理的数据本身的内禀性质，想办法在网络设计中融入这种性质。\n",
    "\n",
    "这里，我们把数据所具有的内禀属性——对称性，和归纳偏置联系起来。\n",
    "\n",
    "对对称性的广义描述是，当数据经历某种形式的变换时，它的性质大概保持不变。比如（见下图）\n",
    "\n",
    " - 把图片中一个元素从左边移到右边，图片本身性质大概保持不变。\n",
    " - 把粒子构成的数据中任意两个粒子记录进行交换，数据本身性质保持严格不变（也即，粒子在数据中本身是无序的）。\n",
    " - 把粒子构成的数据整体进行 Lorentz 变换，其数据性质也大概保持不变。\n",
    "\n",
    "<img src=\"figures/inherit-symm.png\" alt=\"image\" width=600/>\n",
    "\n",
    "所以我们可以想办法把这些数据内禀的特征作为“知识”来教给网络。一种方法是，在设计时给网络一定的约束（给网络inductive bias），使得当数据经历这些变换时，网络本身的部分或全部神经元输出保持不变，这就增强了网络对这种变换的稳健性，让网络大概“知道了数据有这样的内禀属性，经历变换后其性质大概保持不变”。\n",
    "\n",
    "因此，我们可以工程上解释为什么CNN在早期视觉领域非常有优势；粒子物理为什么从CNN/RNN网络转移到了满足粒子交换不变的GNN网络以获得更好性能。\n",
    "\n",
    "对于最后一点，我们可以设计增强Lorentz对称性的网络来提升其性能（这在 [CL *et al*. PRD. 109, 056003 (2024)](https://arxiv.org/abs/2208.07814) 中有所讨论）。最简单的方法就是，给网络的输入增添很多Lorentz标量，因为这些标量是Lorentz不变量，能够增强网络的稳健性。对于包含 $N$ 粒子记录的数据，可以构造 $N^2$ 个粒子对的不变质量，它是所有可构造的洛伦兹标量的一组基底。因此，可以把这 $N^2$ 个初始变量经过 embed 之后（维度为 $(N,N,d)$），加入attention score中偏移它，从而影响attention weight。\n",
    "\n",
    "以上可以认为是Particle Transformer的基本设计理念，以解释它性能的优势来源（ParT除了加入不变质量，还有额外3个特征输入，它们也具备一些变换的不变性；以及，ParT还做了大量的工程学优化，都有助于提升其性能）\n",
    "\n",
    "<img src=\"figures/part-pairwise-feat.png\" alt=\"image\" width=600/>\n",
    "\n",
    "我们简单地改造上一节最后做的Transformer，这里仅多做三件事：\n",
    "\n",
    " - 计算 $N^2$ 个粒子对的不变质量\n",
    " - 用一个额外的 embeder，将其嵌入到 $d_{\\rm pair}=4$ 维的潜空间中 dim=$(N,N,d_{\\rm pair}=4)$\n",
    " - 把它注入作为每层 Transformer block 的attention计算中，分别加到4个head的attention score上（各自是$(N,N)$的矩阵）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如果在 Google Colab 中使用，请首先运行下面的命令下载所需数据集。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! if [[ \"$(hostname)\" != *pku.edu.cn* && \"$(hostname)\" != *lxlogin* ]]; then \\\n",
    "    wget https://coli.web.cern.ch/coli/share/cmschina/ML/dihiggs_ntuples/hh2b2w.root; \\\n",
    "    wget https://coli.web.cern.ch/coli/share/cmschina/ML/dihiggs_ntuples/ttbar.root; \\\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载上一节中的 di-Higgs vs ttbar 的数据并对特征进行标准化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>is_sig</th>\n",
       "      <th>is_bkg</th>\n",
       "      <th>bjet1_pt</th>\n",
       "      <th>bjet1_eta</th>\n",
       "      <th>bjet1_phi</th>\n",
       "      <th>bjet1_eratio</th>\n",
       "      <th>bjet1_mass</th>\n",
       "      <th>bjet1_ncharged</th>\n",
       "      <th>bjet1_nneutrals</th>\n",
       "      <th>...</th>\n",
       "      <th>lep1_charge</th>\n",
       "      <th>lep1_type</th>\n",
       "      <th>lep2_pt</th>\n",
       "      <th>lep2_phi</th>\n",
       "      <th>lep2_eta</th>\n",
       "      <th>lep2_charge</th>\n",
       "      <th>lep2_type</th>\n",
       "      <th>met</th>\n",
       "      <th>met_phi</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>191.402328</td>\n",
       "      <td>-0.291164</td>\n",
       "      <td>-0.979666</td>\n",
       "      <td>0.289940</td>\n",
       "      <td>16.695002</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.508558</td>\n",
       "      <td>1.165262</td>\n",
       "      <td>-0.711694</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>233.613846</td>\n",
       "      <td>2.300718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>68.452507</td>\n",
       "      <td>-1.215415</td>\n",
       "      <td>2.387005</td>\n",
       "      <td>0.492361</td>\n",
       "      <td>15.253864</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50.567219</td>\n",
       "      <td>-1.089323</td>\n",
       "      <td>0.409210</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>102.682526</td>\n",
       "      <td>-0.004101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>152.725433</td>\n",
       "      <td>0.449958</td>\n",
       "      <td>-1.470235</td>\n",
       "      <td>1.215402</td>\n",
       "      <td>12.211457</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43.384056</td>\n",
       "      <td>0.584961</td>\n",
       "      <td>0.624317</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.796436</td>\n",
       "      <td>0.935978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>107.360390</td>\n",
       "      <td>0.124028</td>\n",
       "      <td>-1.175005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.060685</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.664654</td>\n",
       "      <td>2.175398</td>\n",
       "      <td>0.556468</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>65.674774</td>\n",
       "      <td>1.417736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>97.040932</td>\n",
       "      <td>2.160315</td>\n",
       "      <td>-2.940341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.475123</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.825296</td>\n",
       "      <td>0.306789</td>\n",
       "      <td>0.310836</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94.994255</td>\n",
       "      <td>-3.043913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>149995</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>169.980515</td>\n",
       "      <td>-0.147777</td>\n",
       "      <td>2.985398</td>\n",
       "      <td>0.209411</td>\n",
       "      <td>27.176857</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>92.388741</td>\n",
       "      <td>-0.697610</td>\n",
       "      <td>0.483596</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131.839859</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>149996</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>47.205002</td>\n",
       "      <td>1.002193</td>\n",
       "      <td>-1.613720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.505911</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.515564</td>\n",
       "      <td>0.693190</td>\n",
       "      <td>0.890577</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75.465065</td>\n",
       "      <td>1.878048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>149997</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>63.940311</td>\n",
       "      <td>0.381228</td>\n",
       "      <td>0.494209</td>\n",
       "      <td>0.166411</td>\n",
       "      <td>8.920477</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34.591877</td>\n",
       "      <td>2.737549</td>\n",
       "      <td>-0.180914</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>59.409447</td>\n",
       "      <td>0.176429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>149998</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>89.012772</td>\n",
       "      <td>-0.562279</td>\n",
       "      <td>-0.638000</td>\n",
       "      <td>0.648749</td>\n",
       "      <td>13.602261</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.882822</td>\n",
       "      <td>-3.140386</td>\n",
       "      <td>-1.086141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44.600636</td>\n",
       "      <td>-1.177096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>149999</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>100.859207</td>\n",
       "      <td>-1.141927</td>\n",
       "      <td>-1.177283</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>11.631890</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>51.515999</td>\n",
       "      <td>0.453256</td>\n",
       "      <td>-1.976577</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73.958908</td>\n",
       "      <td>-2.497298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         event  is_sig  is_bkg    bjet1_pt  bjet1_eta  bjet1_phi  \\\n",
       "0            0    True   False  191.402328  -0.291164  -0.979666   \n",
       "1            1    True   False   68.452507  -1.215415   2.387005   \n",
       "2            2    True   False  152.725433   0.449958  -1.470235   \n",
       "3            3    True   False  107.360390   0.124028  -1.175005   \n",
       "4            4    True   False   97.040932   2.160315  -2.940341   \n",
       "...        ...     ...     ...         ...        ...        ...   \n",
       "149995  149995   False    True  169.980515  -0.147777   2.985398   \n",
       "149996  149996   False    True   47.205002   1.002193  -1.613720   \n",
       "149997  149997   False    True   63.940311   0.381228   0.494209   \n",
       "149998  149998   False    True   89.012772  -0.562279  -0.638000   \n",
       "149999  149999   False    True  100.859207  -1.141927  -1.177283   \n",
       "\n",
       "        bjet1_eratio  bjet1_mass  bjet1_ncharged  bjet1_nneutrals  ...  \\\n",
       "0           0.289940   16.695002              12                6  ...   \n",
       "1           0.492361   15.253864              10               10  ...   \n",
       "2           1.215402   12.211457              12                8  ...   \n",
       "3           0.000000    6.060685               6                4  ...   \n",
       "4           0.000000   10.475123              10               14  ...   \n",
       "...              ...         ...             ...              ...  ...   \n",
       "149995      0.209411   27.176857              12                8  ...   \n",
       "149996      0.000000    9.505911              10                8  ...   \n",
       "149997      0.166411    8.920477              10                8  ...   \n",
       "149998      0.648749   13.602261              11               12  ...   \n",
       "149999      0.068802   11.631890               6               12  ...   \n",
       "\n",
       "        lep1_charge  lep1_type    lep2_pt  lep2_phi  lep2_eta  lep2_charge  \\\n",
       "0                 1          0  17.508558  1.165262 -0.711694           -1   \n",
       "1                 1          1  50.567219 -1.089323  0.409210           -1   \n",
       "2                 1          1  43.384056  0.584961  0.624317           -1   \n",
       "3                 1          1  26.664654  2.175398  0.556468           -1   \n",
       "4                -1          1  29.825296  0.306789  0.310836            1   \n",
       "...             ...        ...        ...       ...       ...          ...   \n",
       "149995           -1          1  92.388741 -0.697610  0.483596            1   \n",
       "149996           -1          0  62.515564  0.693190  0.890577            1   \n",
       "149997            1          0  34.591877  2.737549 -0.180914           -1   \n",
       "149998           -1          1  20.882822 -3.140386 -1.086141            1   \n",
       "149999           -1          1  51.515999  0.453256 -1.976577            1   \n",
       "\n",
       "        lep2_type         met   met_phi  label  \n",
       "0               0  233.613846  2.300718      1  \n",
       "1               1  102.682526 -0.004101      1  \n",
       "2               0   57.796436  0.935978      1  \n",
       "3               1   65.674774  1.417736      1  \n",
       "4               0   94.994255 -3.043913      1  \n",
       "...           ...         ...       ...    ...  \n",
       "149995          1  131.839859 -0.000835      0  \n",
       "149996          0   75.465065  1.878048      0  \n",
       "149997          1   59.409447  0.176429      0  \n",
       "149998          0   44.600636 -1.177096      0  \n",
       "149999          1   73.958908 -2.497298      0  \n",
       "\n",
       "[300000 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "import os\n",
    "# Determine the base directory and the remote git path\n",
    "hostname = os.uname()[1]\n",
    "if 'pku.edu.cn' in hostname: # on PKU cluster\n",
    "    basedir = '/data/pubfs/pku_visitor/public_write/ML/dihiggs_ntuples/'\n",
    "elif hostname.startswith('lxlogin'): # on IHEP lxlogin\n",
    "    basedir = '/scratchfs/cms/licq/cmschina/ML/dihiggs_ntuples/'\n",
    "else:\n",
    "    basedir = '.'\n",
    "\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "dihiggs = uproot.concatenate(f\"{basedir}/hh2b2w.root:tree\",library=\"pd\")\n",
    "ttbar = uproot.concatenate(f\"{basedir}/ttbar.root:tree\",library=\"pd\")\n",
    "\n",
    "df_raw = pd.concat([dihiggs, ttbar], axis=0)\n",
    "df_raw['label'] = df_raw['is_sig'].astype(int) # 定义一个int类型的label，指示是sig还是bkg\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bjet1_pt_trans</th>\n",
       "      <th>bjet1_eta_trans</th>\n",
       "      <th>bjet1_phi_trans</th>\n",
       "      <th>bjet1_eratio_trans</th>\n",
       "      <th>bjet1_mass_trans</th>\n",
       "      <th>bjet1_ncharged_trans</th>\n",
       "      <th>bjet1_nneutrals_trans</th>\n",
       "      <th>bjet2_pt_trans</th>\n",
       "      <th>bjet2_eta_trans</th>\n",
       "      <th>bjet2_phi_trans</th>\n",
       "      <th>...</th>\n",
       "      <th>lep1_charge</th>\n",
       "      <th>lep1_type</th>\n",
       "      <th>lep2_pt</th>\n",
       "      <th>lep2_phi</th>\n",
       "      <th>lep2_eta</th>\n",
       "      <th>lep2_charge</th>\n",
       "      <th>lep2_type</th>\n",
       "      <th>met</th>\n",
       "      <th>met_phi</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566009</td>\n",
       "      <td>-0.216940</td>\n",
       "      <td>-0.538931</td>\n",
       "      <td>-0.142020</td>\n",
       "      <td>0.165628</td>\n",
       "      <td>0.430743</td>\n",
       "      <td>-0.663944</td>\n",
       "      <td>-0.127634</td>\n",
       "      <td>-1.025722</td>\n",
       "      <td>-0.312706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.508558</td>\n",
       "      <td>1.165262</td>\n",
       "      <td>-0.711694</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>233.613846</td>\n",
       "      <td>2.300718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.692736</td>\n",
       "      <td>-0.913453</td>\n",
       "      <td>1.316571</td>\n",
       "      <td>-0.140433</td>\n",
       "      <td>0.032240</td>\n",
       "      <td>0.037705</td>\n",
       "      <td>0.213418</td>\n",
       "      <td>-0.177743</td>\n",
       "      <td>-0.332485</td>\n",
       "      <td>-1.051495</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50.567219</td>\n",
       "      <td>-1.089323</td>\n",
       "      <td>0.409210</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>102.682526</td>\n",
       "      <td>-0.004101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.170040</td>\n",
       "      <td>0.341568</td>\n",
       "      <td>-0.809302</td>\n",
       "      <td>-0.134763</td>\n",
       "      <td>-0.249359</td>\n",
       "      <td>0.430743</td>\n",
       "      <td>-0.225263</td>\n",
       "      <td>-0.270861</td>\n",
       "      <td>0.921192</td>\n",
       "      <td>-1.382473</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43.384056</td>\n",
       "      <td>0.584961</td>\n",
       "      <td>0.624317</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.796436</td>\n",
       "      <td>0.935978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.294402</td>\n",
       "      <td>0.095947</td>\n",
       "      <td>-0.646589</td>\n",
       "      <td>-0.144293</td>\n",
       "      <td>-0.818660</td>\n",
       "      <td>-0.748372</td>\n",
       "      <td>-1.102625</td>\n",
       "      <td>-0.959167</td>\n",
       "      <td>1.114436</td>\n",
       "      <td>-0.866333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.664654</td>\n",
       "      <td>2.175398</td>\n",
       "      <td>0.556468</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>65.674774</td>\n",
       "      <td>1.417736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.400051</td>\n",
       "      <td>1.630488</td>\n",
       "      <td>-1.619534</td>\n",
       "      <td>-0.144293</td>\n",
       "      <td>-0.410070</td>\n",
       "      <td>0.037705</td>\n",
       "      <td>1.090781</td>\n",
       "      <td>-0.542826</td>\n",
       "      <td>1.505292</td>\n",
       "      <td>-0.814446</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.825296</td>\n",
       "      <td>0.306789</td>\n",
       "      <td>0.310836</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94.994255</td>\n",
       "      <td>-3.043913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>0.346695</td>\n",
       "      <td>-0.108884</td>\n",
       "      <td>1.646368</td>\n",
       "      <td>-0.142651</td>\n",
       "      <td>1.135805</td>\n",
       "      <td>0.430743</td>\n",
       "      <td>-0.225263</td>\n",
       "      <td>0.927557</td>\n",
       "      <td>0.108459</td>\n",
       "      <td>-1.172372</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>92.388741</td>\n",
       "      <td>-0.697610</td>\n",
       "      <td>0.483596</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131.839859</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>-0.910265</td>\n",
       "      <td>0.757730</td>\n",
       "      <td>-0.888382</td>\n",
       "      <td>-0.144293</td>\n",
       "      <td>-0.499778</td>\n",
       "      <td>0.037705</td>\n",
       "      <td>-0.225263</td>\n",
       "      <td>-0.592341</td>\n",
       "      <td>2.543271</td>\n",
       "      <td>0.839254</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.515564</td>\n",
       "      <td>0.693190</td>\n",
       "      <td>0.890577</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75.465065</td>\n",
       "      <td>1.878048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>-0.738931</td>\n",
       "      <td>0.289773</td>\n",
       "      <td>0.273378</td>\n",
       "      <td>-0.142988</td>\n",
       "      <td>-0.553964</td>\n",
       "      <td>0.037705</td>\n",
       "      <td>-0.225263</td>\n",
       "      <td>-0.640201</td>\n",
       "      <td>-0.014030</td>\n",
       "      <td>-0.854679</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34.591877</td>\n",
       "      <td>2.737549</td>\n",
       "      <td>-0.180914</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>59.409447</td>\n",
       "      <td>0.176429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>-0.482243</td>\n",
       "      <td>-0.421251</td>\n",
       "      <td>-0.350626</td>\n",
       "      <td>-0.139206</td>\n",
       "      <td>-0.120629</td>\n",
       "      <td>0.234224</td>\n",
       "      <td>0.652100</td>\n",
       "      <td>-0.176126</td>\n",
       "      <td>-0.564892</td>\n",
       "      <td>0.026914</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.882822</td>\n",
       "      <td>-3.140386</td>\n",
       "      <td>-1.086141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44.600636</td>\n",
       "      <td>-1.177096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>-0.360960</td>\n",
       "      <td>-0.858072</td>\n",
       "      <td>-0.647845</td>\n",
       "      <td>-0.143754</td>\n",
       "      <td>-0.303002</td>\n",
       "      <td>-0.748372</td>\n",
       "      <td>0.652100</td>\n",
       "      <td>-0.024667</td>\n",
       "      <td>-0.532425</td>\n",
       "      <td>1.056635</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>51.515999</td>\n",
       "      <td>0.453256</td>\n",
       "      <td>-1.976577</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73.958908</td>\n",
       "      <td>-2.497298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bjet1_pt_trans  bjet1_eta_trans  bjet1_phi_trans  bjet1_eratio_trans  \\\n",
       "0             0.566009        -0.216940        -0.538931           -0.142020   \n",
       "1            -0.692736        -0.913453         1.316571           -0.140433   \n",
       "2             0.170040         0.341568        -0.809302           -0.134763   \n",
       "3            -0.294402         0.095947        -0.646589           -0.144293   \n",
       "4            -0.400051         1.630488        -1.619534           -0.144293   \n",
       "...                ...              ...              ...                 ...   \n",
       "149995        0.346695        -0.108884         1.646368           -0.142651   \n",
       "149996       -0.910265         0.757730        -0.888382           -0.144293   \n",
       "149997       -0.738931         0.289773         0.273378           -0.142988   \n",
       "149998       -0.482243        -0.421251        -0.350626           -0.139206   \n",
       "149999       -0.360960        -0.858072        -0.647845           -0.143754   \n",
       "\n",
       "        bjet1_mass_trans  bjet1_ncharged_trans  bjet1_nneutrals_trans  \\\n",
       "0               0.165628              0.430743              -0.663944   \n",
       "1               0.032240              0.037705               0.213418   \n",
       "2              -0.249359              0.430743              -0.225263   \n",
       "3              -0.818660             -0.748372              -1.102625   \n",
       "4              -0.410070              0.037705               1.090781   \n",
       "...                  ...                   ...                    ...   \n",
       "149995          1.135805              0.430743              -0.225263   \n",
       "149996         -0.499778              0.037705              -0.225263   \n",
       "149997         -0.553964              0.037705              -0.225263   \n",
       "149998         -0.120629              0.234224               0.652100   \n",
       "149999         -0.303002             -0.748372               0.652100   \n",
       "\n",
       "        bjet2_pt_trans  bjet2_eta_trans  bjet2_phi_trans  ...  lep1_charge  \\\n",
       "0            -0.127634        -1.025722        -0.312706  ...            1   \n",
       "1            -0.177743        -0.332485        -1.051495  ...            1   \n",
       "2            -0.270861         0.921192        -1.382473  ...            1   \n",
       "3            -0.959167         1.114436        -0.866333  ...            1   \n",
       "4            -0.542826         1.505292        -0.814446  ...           -1   \n",
       "...                ...              ...              ...  ...          ...   \n",
       "149995        0.927557         0.108459        -1.172372  ...           -1   \n",
       "149996       -0.592341         2.543271         0.839254  ...           -1   \n",
       "149997       -0.640201        -0.014030        -0.854679  ...            1   \n",
       "149998       -0.176126        -0.564892         0.026914  ...           -1   \n",
       "149999       -0.024667        -0.532425         1.056635  ...           -1   \n",
       "\n",
       "        lep1_type    lep2_pt  lep2_phi  lep2_eta  lep2_charge  lep2_type  \\\n",
       "0               0  17.508558  1.165262 -0.711694           -1          0   \n",
       "1               1  50.567219 -1.089323  0.409210           -1          1   \n",
       "2               1  43.384056  0.584961  0.624317           -1          0   \n",
       "3               1  26.664654  2.175398  0.556468           -1          1   \n",
       "4               1  29.825296  0.306789  0.310836            1          0   \n",
       "...           ...        ...       ...       ...          ...        ...   \n",
       "149995          1  92.388741 -0.697610  0.483596            1          1   \n",
       "149996          0  62.515564  0.693190  0.890577            1          0   \n",
       "149997          0  34.591877  2.737549 -0.180914           -1          1   \n",
       "149998          1  20.882822 -3.140386 -1.086141            1          0   \n",
       "149999          1  51.515999  0.453256 -1.976577            1          1   \n",
       "\n",
       "               met   met_phi  label  \n",
       "0       233.613846  2.300718      1  \n",
       "1       102.682526 -0.004101      1  \n",
       "2        57.796436  0.935978      1  \n",
       "3        65.674774  1.417736      1  \n",
       "4        94.994255 -3.043913      1  \n",
       "...            ...       ...    ...  \n",
       "149995  131.839859 -0.000835      0  \n",
       "149996   75.465065  1.878048      0  \n",
       "149997   59.409447  0.176429      0  \n",
       "149998   44.600636 -1.177096      0  \n",
       "149999   73.958908 -2.497298      0  \n",
       "\n",
       "[300000 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "input_columns = ['bjet1_pt', 'bjet1_eta', 'bjet1_phi',\n",
    "       'bjet1_eratio', 'bjet1_mass', 'bjet1_ncharged', 'bjet1_nneutrals',\n",
    "       'bjet2_pt', 'bjet2_eta', 'bjet2_phi', 'bjet2_eratio', 'bjet2_mass',\n",
    "       'bjet2_ncharged', 'bjet2_nneutrals', 'lep1_pt', 'lep1_phi', 'lep1_eta',\n",
    "       'lep1_charge', 'lep1_type', 'lep2_pt', 'lep2_phi', 'lep2_eta',\n",
    "       'lep2_charge', 'lep2_type', 'met', 'met_phi']\n",
    "\n",
    "# Fit and transform the DataFrame\n",
    "df = pd.DataFrame(scaler.fit_transform(df_raw[input_columns]), columns=[c + '_trans' for c in input_columns], index=df_raw.index)\n",
    "df = pd.concat([df, df_raw], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先制作新的 PyTorch dataset。我们考虑在从 Dataset 取数的时候，就已经可以拿到5个token（2个b-jet，2个lep，1个MET），获得它们各自的features（分别是7/5/2维）、vectors（4动量，都是4维）。\n",
    "\n",
    "> 此外，还额外输出了points变量（在η-φ坐标的位置）。定义这个新的 PyTorch Dataset 有额外的好处，就是和 ParT 和 ParticleNet 的标准模型文件接受的输入一致了，可以方便我们在下面一个小节直接用这个 Dataset。这个 Dataset 输出的格式是 (points, features, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "\n",
    "def _p4_from_ptetaphim(pt, eta, phi, mass):\n",
    "    import vector\n",
    "    vector.register_awkward()\n",
    "    return vector.zip({'pt': pt, 'eta': eta, 'phi': phi, 'm': mass})\n",
    "\n",
    "class DataFrameTokenizedDataset(Dataset):\n",
    "    def __init__(self, dataframe, input_columns, input_columns_raw, target_column):\n",
    "        print('Initializing DataFrameTokenizedDataset...')\n",
    "        self.dataframe = dataframe\n",
    "        self.targets = dataframe[target_column].values\n",
    "\n",
    "        # With inputs, we define three sets of tokenized data: features, vectors, and points\n",
    "        inputs = dataframe[input_columns].values\n",
    "        inputs_raw = dataframe[input_columns_raw].values\n",
    "        N = len(dataframe)\n",
    "\n",
    "        # Define tokenized input \"features\" with dim (N, L=5, d=7)\n",
    "        features = [\n",
    "            inputs[:,0:7], # dim (N, 7)\n",
    "            inputs[:,7:14],\n",
    "            np.concatenate([inputs[:,14:19], np.zeros([N, 2])], axis=1),\n",
    "            np.concatenate([inputs[:,19:24], np.zeros([N, 2])], axis=1),\n",
    "            np.concatenate([inputs[:,24:26], np.zeros([N, 5])], axis=1),\n",
    "        ]\n",
    "        self.features = torch.tensor(np.stack(features, axis=1), dtype=torch.float32)\n",
    "        print('  features:', self.features.shape)\n",
    "\n",
    "        # Define tokenized \"vectors\" with dim (N, L=5, d=4), d=4 for (px, py, pz, energy)\n",
    "        zeros = np.zeros(N, dtype=np.float32)\n",
    "        pt = np.stack([inputs_raw[:,0], inputs_raw[:,7], inputs_raw[:,14], inputs_raw[:,19], inputs_raw[:,24]], axis=-1) # dim (N, 5)\n",
    "        eta = np.stack([inputs_raw[:,1], inputs_raw[:,8], inputs_raw[:,16], inputs_raw[:,21], zeros], axis=-1)\n",
    "        phi = np.stack([inputs_raw[:,2], inputs_raw[:,9], inputs_raw[:,15], inputs_raw[:,20], inputs_raw[:,25]], axis=-1)\n",
    "        mass = np.stack([inputs_raw[:,4], inputs_raw[:,11], zeros, zeros, zeros], axis=-1)\n",
    "        p4 = _p4_from_ptetaphim(pt, eta, phi, mass)\n",
    "        self.vectors = torch.tensor(np.stack([p4.px, p4.py, p4.pz, p4.energy], axis=-1), dtype=torch.float32)\n",
    "        print('  vectors:', self.vectors.shape)\n",
    "\n",
    "        # Define tokenized \"points\" with dim (N, L=5, d=2), d=2 for (eta, phi)\n",
    "        self.points = torch.tensor(np.stack([eta, phi], axis=-1), dtype=torch.float32)\n",
    "        print('  points:', self.points.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        points = self.points[idx]\n",
    "        features = self.features[idx]\n",
    "        vectors = self.vectors[idx]        \n",
    "        y = torch.tensor(self.targets[idx], dtype=torch.long) # 一维的label\n",
    "        return (points, features, vectors), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DataFrameTokenizedDataset...\n",
      "  features: torch.Size([240000, 5, 7])\n",
      "  vectors: torch.Size([240000, 5, 4])\n",
      "  points: torch.Size([240000, 5, 2])\n",
      "Initializing DataFrameTokenizedDataset...\n",
      "  features: torch.Size([30000, 5, 7])\n",
      "  vectors: torch.Size([30000, 5, 4])\n",
      "  points: torch.Size([30000, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "input_columns = ['bjet1_pt', 'bjet1_eta', 'bjet1_phi',\n",
    "       'bjet1_eratio', 'bjet1_mass', 'bjet1_ncharged', 'bjet1_nneutrals',\n",
    "       'bjet2_pt', 'bjet2_eta', 'bjet2_phi', 'bjet2_eratio', 'bjet2_mass',\n",
    "       'bjet2_ncharged', 'bjet2_nneutrals', 'lep1_pt', 'lep1_phi', 'lep1_eta',\n",
    "       'lep1_charge', 'lep1_type', 'lep2_pt', 'lep2_phi', 'lep2_eta',\n",
    "       'lep2_charge', 'lep2_type', 'met', 'met_phi']\n",
    "target_column = 'label'\n",
    "\n",
    "# Split the data into training/validation/testing datasets following 80/10/10%\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = DataFrameTokenizedDataset(train_df, [c + '_trans' for c in input_columns], input_columns, target_column)\n",
    "val_dataset = DataFrameTokenizedDataset(val_df, [c + '_trans' for c in input_columns], input_columns, target_column)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于这个 Dataset 输出的 `features`，可以做新的 Transformer 的 token embeder。\n",
    "\n",
    "从 Dataset 中输出的 batched sample，`features` 应该具有的维度是 `(batch_size, num_input_token=5, input_size=7)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = nn.ModuleDict()\n",
    "        for token_name, in_dim in zip(['bjet', 'lep', 'met'], [7, 5, 2]):\n",
    "            # embedding layers for three types of tokens: bjet, lep, met, with input vector dim 7, 5, 2\n",
    "            self.token_embeddings[token_name] = nn.Sequential(\n",
    "                nn.Linear(in_dim, config.hidden_size),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            )\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        # add a trainable class token\n",
    "        self.class_token = nn.Parameter(torch.randn(1, config.hidden_size))\n",
    "\n",
    "    def forward(self, features):\n",
    "        # features have size (batch_size, num_input_token=5, input_size=7)\n",
    "        feat_bjet1, feat_bjet2, feat_lep1, feat_lep2, feat_met = features.unbind(dim=1) # each with dim (batch_size, 7)\n",
    "        embeddings = []\n",
    "        embeddings.append(self.class_token.expand(features.size(0), -1)) # first token is the [CLS] token\n",
    "        embeddings.append(self.token_embeddings['bjet'](feat_bjet1)) # bjet1 token embed by bjet embedding layer\n",
    "        embeddings.append(self.token_embeddings['bjet'](feat_bjet2)) # bjet2 token embed by bjet embedding layer\n",
    "        embeddings.append(self.token_embeddings['lep'](feat_lep1[:, :5])) # lep1 token embed by lep embedding layer\n",
    "        embeddings.append(self.token_embeddings['lep'](feat_lep2[:, :5])) # lep2 token embed by lep embedding layer\n",
    "        embeddings.append(self.token_embeddings['met'](feat_met[:, :2])) # met token embed by met embedding layer\n",
    "        embeddings = torch.stack(embeddings, dim=1)\n",
    "        # now embeddings has dim (batch_size, num_tokens=6, hidden_size)\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后是我们修改后的 Transformer。\n",
    "\n",
    " - 首先，对于基础的 Transformer block，我们使用 `nn.MultiheadAttention` 自带的功能，其正向计算可以额外接受一个 `attn_mask` 变量，它是 `(batch_size * num_heads, num_tokens, num_tokens)` 维度的，目的正是给 `num_heads` 个 attention score添加额外的偏置。\n",
    "\n",
    "   > 参考 https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html\n",
    "\n",
    "     - *`attn_mask`*: If specified, a 2D or 3D mask preventing attention to certain positions. Must be of shape\n",
    "        $(L, S)$ or $(N\\cdot\\text{num\\_heads}, L, S)$, where $N$  is the batch size,\n",
    "        $L$ is the target sequence length, and $S$ is the source sequence length. A 2D mask will be\n",
    "        broadcasted across the batch while a 3D mask allows for a different mask for each entry in the batch.\n",
    "        Binary and float masks are supported. For a binary mask, a `True` value indicates that the\n",
    "        corresponding position is not allowed to attend. For a float mask, the mask values will be added to\n",
    "        the attention weight.\n",
    "\n",
    " - 然后，通过 `get_attention_bias(vectors)` 函数，可以利用每个输入 token 的4-动量，计算得到 $N^2$ 个粒子对4-动量和的不变质量。这里用到了 broadcast 的性质。\n",
    "   > 实现方案：`to_m2(v.unsqueeze(-2) + v.unsqueeze(-3), eps=1e-8)`\n",
    "\n",
    "    将它进行 embed 后，当做 `attn_mask` 输入给 Transformer block 即可。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTransformerWithAttnBiasBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_hidden_dim, attn_dropout=0.1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout=attn_dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(ff_hidden_dim, embed_dim)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # inputs: \n",
    "        #   x: (batch_size, num_tokens, embed_dim)\n",
    "        #   attn_mask: (batch_size * num_heads, num_tokens, num_tokens)\n",
    "\n",
    "        # Self-attention\n",
    "        x = self.norm1(x) # the first layernorm\n",
    "        attn_output, _ = self.attention(x, x, x, need_weights=False, attn_mask=attn_mask) # input Q, K, V are the same\n",
    "        x = x + self.dropout(attn_output) # the first residual connection\n",
    "\n",
    "        # Feed-forward\n",
    "        x = self.norm2(x) # the second layernorm\n",
    "        ff_output = self.ff(x)\n",
    "        x = x + self.dropout(ff_output) # the second residual connection\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def to_m2(x, eps=1e-8):\n",
    "    m2 = x[..., 3:4].square() - x[..., :3].square().sum(dim=-1, keepdim=True)\n",
    "    return m2.clamp(min=eps)\n",
    "\n",
    "class BasicTransformerWithAttnBiasForClassification(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embeddings = TokenEmbeddings(config) # the same Embeddings module as before\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [BasicTransformerWithAttnBiasBlock(config.hidden_size, config.num_attention_heads, config.intermediate_size, attn_dropout=0., dropout=config.hidden_dropout_prob) \n",
    "             for _ in range(config.num_hidden_layers)]\n",
    "            )\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.use_attention_bias = config.use_attention_bias\n",
    "\n",
    "        if self.use_attention_bias:\n",
    "            self.pair_embedding = nn.Sequential(\n",
    "                nn.Linear(1, config.pair_hidden_size),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(config.pair_hidden_size, config.num_attention_heads),\n",
    "            )\n",
    "\n",
    "    def get_attention_bias(self, vectors):\n",
    "        # Calculate pairwise masses and embed them, from vectors: (batch_size, num_tokens, 4)\n",
    "\n",
    "        v = torch.cat([torch.zeros_like(vectors[:, :1]), vectors], dim=1) # add zero vector for the [CLS] token\n",
    "        # broadcast the vectors to all pairs\n",
    "        # note: \n",
    "        #   v.unsqueeze(-2) has shape (batch_size, num_tokens, 1, 4)\n",
    "        #   v.unsqueeze(-3) has shape (batch_size, 1, num_tokens, 4)\n",
    "        lnm2 = torch.log(to_m2(v.unsqueeze(-2) + v.unsqueeze(-3), eps=1e-8) + 1) # dim: (batch_size, num_tokens, num_tokens, 1)\n",
    "\n",
    "        output = self.pair_embedding(lnm2).permute(0, 3, 1, 2).reshape(-1, v.size(1), v.size(1)) # dim: (batch_size * num_attention_heads, num_tokens, num_tokens)\n",
    "        return output\n",
    "\n",
    "    def forward(self, points, features, vectors):\n",
    "        x = self.embeddings(features)\n",
    "        attn_mask = self.get_attention_bias(vectors) if self.use_attention_bias else None\n",
    "        for block in self.blocks:\n",
    "            x = block(x, attn_mask=attn_mask)\n",
    "        x = x[:, 0, :] # select hidden state of [CLS] token\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们定义下这个模型，看下模型的实力！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicTransformerWithAttnBias(\n",
      "  (mod): BasicTransformerWithAttnBiasForClassification(\n",
      "    (embeddings): TokenEmbeddings(\n",
      "      (token_embeddings): ModuleDict(\n",
      "        (bjet): Sequential(\n",
      "          (0): Linear(in_features=7, out_features=16, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "        (lep): Sequential(\n",
      "          (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "        (met): Sequential(\n",
      "          (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0-3): 4 x BasicTransformerWithAttnBiasBlock(\n",
      "        (attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (ff): Sequential(\n",
      "          (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (classifier): Linear(in_features=16, out_features=2, bias=True)\n",
      "    (pair_embedding): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (train_acc): MulticlassAccuracy()\n",
      "  (val_acc): MulticlassAccuracy()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "config = SimpleNamespace(\n",
    "    hidden_size = 16,  # Hidden size for embeddings and Transformer\n",
    "    num_attention_heads = 4,  # Number of attention heads\n",
    "    intermediate_size = 32,  # Feed forward intermediate size\n",
    "    num_hidden_layers = 4,  # Number of Transformer layers\n",
    "    hidden_dropout_prob = 0.,  # Dropout probability\n",
    "    num_labels = 2,  # Number of output classes\n",
    "\n",
    "    # new config for pairwise mass embedding\n",
    "    use_attention_bias = True,  # Whether to use attention bias\n",
    "    pair_hidden_size = 8,  # Hidden size for pairwise mass embedding\n",
    ")\n",
    "\n",
    "# Define the PyTorch Lightning model\n",
    "class BasicTransformerWithAttnBias(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.mod = BasicTransformerWithAttnBiasForClassification(config)\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=config.num_labels)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=config.num_labels)\n",
    "\n",
    "    def forward(self, *x):\n",
    "        return self.mod(*x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch # x: a tuple of (points, features, vectors), y: label\n",
    "        logits = self(*x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.train_acc(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True)\n",
    "        self.log('lr', self.trainer.optimizers[0].param_groups[0]['lr'])\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch # x: a tuple of (points, features, vectors), y: label\n",
    "        logits = self(*x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.val_acc(logits, y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        \n",
    "        def lr_lambda(epoch):\n",
    "            if epoch < 0.7 * self.trainer.max_epochs:\n",
    "                return 1.0\n",
    "            else:\n",
    "                decay_factor = (epoch - 0.7 * self.trainer.max_epochs) / (0.3 * self.trainer.max_epochs)\n",
    "                return 0.01 ** decay_factor\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "# 定义model的实例\n",
    "model_transformer_attnbias = BasicTransformerWithAttnBias(config)\n",
    "\n",
    "# 打印下这个模型进行检查\n",
    "print(model_transformer_attnbias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type                                          | Params | Mode \n",
      "------------------------------------------------------------------------------------\n",
      "0 | mod       | BasicTransformerWithAttnBiasForClassification | 10.1 K | train\n",
      "1 | train_acc | MulticlassAccuracy                            | 0      | train\n",
      "2 | val_acc   | MulticlassAccuracy                            | 0      | train\n",
      "------------------------------------------------------------------------------------\n",
      "10.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.1 K    Total params\n",
      "0.040     Total estimated model params size (MB)\n",
      "66        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e265e0e6d8e94aacaab34fe0edf64dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3a6f9e3a2343459b411acd0680c9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a26455c770342908f5f470089288b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c69704a2cd4944b902b290bf5dc878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59caae706baf42348bd86c4005dccb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c335585bba4d58b692578b049a9672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944efcebdc964c8194704f3de251c674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699573b778a44d8b92b089decdca5d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29f228778134ec3904d622752f9e515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910dff7d28af465da8feaa0ceff2ea81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584cc85cabbd4dfaa675d84dacb44d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5401bc10f947f29aced1f15aba904c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3403c2410a5c4c61ae7bda2be29a0f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c61e9b68d243e7baa3c4958027ddf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b31427c72245e69375d1fdd6c03244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd148cff2d74359a40440f60ce6efea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193ef396e6fe417786ec83dc59c02737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8596756bece2435e8d0b61c0849e1225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03814bf3c5524188ba0515a362977e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb808d77a80243da97f3684f9a595915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8539d5dec94020b12cdb4308793006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5318df09b8d54dd58bf3d6cda70eed49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16537ad3a3944a39e31f25ba58ec4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3c2b4a070a4e829aad2d5f861912cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d8db75cd74441394e9ee647f1cc532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b776f673cb47eaa14daa61d7a2313e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35da7cf4992492b986baf28456b1302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d92d1c334894fabb419e81e458c94a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a20060e4a54ce9ad494e7db36f71c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53804d58b81341998c4e38d54ab5188c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239611c3fc3240099956c247db28c819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2882f354cf1d4d9baa1b84580a4b4f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2758cab02047b3992d0f9d16d590b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98af98b3035a4e0daa6ec96cc9670af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ce06a3bc1f4b78acc446bb96bd24df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fddb60f450444c7897f1721acf9f9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b71f24c4cf24779b84b40900e03d174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec628454cf08421ca70fb59809e45387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eae8dcf9ea141f9a2edcc36bcc0113e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f51aca82534ad7b28198a903a175e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f39354879e04d2d89b84f6ef25dbd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8937455199a4b7bb48c238d0c3a23bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b7a95a778a41e6bb1943547d5de513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a39d426f28d468c9f6e860669c555f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4d070458da4481b439b856fdcbaf3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4053595b722e4f4a81b9be694723cc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfcebca2afe64232a2c656a64b059c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f030a18dc8b249beaa41ca59c7ca206a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f3199507744549ad25597cd8c9192e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd05359b5574fb481474c15e202a9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0e9850ebaa486fbb6e0367e9ad4579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9115bea2de484cd088a74cee4d732969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    }
   ],
   "source": [
    "# Trainer with a logger\n",
    "trainer = pl.Trainer(max_epochs=50, logger=pl.loggers.TensorBoardLogger('tb_logs', name='simple_transformer_attnbias'))\n",
    "\n",
    "# Fit the model\n",
    "trainer.fit(model_transformer_attnbias, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过观察 Tensorboard 上面的训练指标，可以看到进步非常显著！\n",
    "这就是简单地把平淡的Transformer，沿着Particle Transformer方向稍作修改后带来的变化。\n",
    "\n",
    "<img src=\"figures/tensorboard_output2.png\" alt=\"image\" width=900/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接入 ParT / ParticleNet 模型\n",
    "\n",
    "利用上面定义的 Dataset，我们可以直接接入标准的 ParT、ParticleNet 模型。原始模型可以在这里下载：\n",
    "https://github.com/hqucms/weaver-core/tree/main/weaver/nn/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如果在 Google Colab 中使用，请首先运行下面的命令下载这些模型文件。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! if [[ \"$(hostname)\" != *pku.edu.cn* && \"$(hostname)\" != *lxlogin* ]]; then \\\n",
    "    wget https://raw.githubusercontent.com/colizz/ml-tutorial/refs/heads/v2025-01-nku/models/ParticleTransformer.py; \\\n",
    "    wget https://raw.githubusercontent.com/colizz/ml-tutorial/refs/heads/v2025-01-nku/models/ParticleNet.py; \\\n",
    "    mkdir models && mv {ParticleTransformer.py,ParticleNet.py} models/; \\\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以直接从文件中加载模型，并初始化模型实例。\n",
    "\n",
    "```python\n",
    "model_part = ParticleTransformerTaggerMultiGroups(\n",
    "    input_dims,\n",
    "    num_classes=num_labels, \n",
    "    embed_dims=[32, 32],\n",
    "    pair_embed_dims=[8, 8],\n",
    "    num_heads=4,\n",
    "    num_layers=4,\n",
    ")\n",
    "```\n",
    "\n",
    "这里有几点说明：\n",
    "\n",
    " - 因为我们的token的特殊性，一共包含3组不同类型的token（`bjet`, `lep`, `met`），它们各自`features` 长度是不一样的（7/5/2）。因此，需要使用 ParT 中对于初始 token 分为多组，每组各自进行 embedding 的实现。其逻辑与我们上面所做是相同的。在 ParT 文件中，我们使用的是额外添加的 `ParticleTransformerTaggerMultiGroups` 的 Module，它支持任意多组 token 的情形。\n",
    "\n",
    " - `ParticleTransformerTaggerMultiGroups` 对于每一组 token 接受三种 input：`features`, `vectors`, `mask`，因此一共需要9个参量作为input。我们的例子中，每个事例都有固定的5个token。mask可以设置为全为1的向量。我们从刚才写的 Dataset 的输出开始，经过一个 `process_model_input(self, x)` 函数，可以得到ParT模型所需的输入特征。\n",
    "\n",
    " - 我们初始化的 ParT 是规模很小的，因为我们的任务并不复杂。可以尝试改变上面的模型初始化参数，来观察训练的效果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the class ParticleNet in models/ParticleNet.py\n",
    "import sys\n",
    "sys.path.append(\"models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParTLightningModel(\n",
      "  (mod): ParticleTransformerTaggerMultiGroups(\n",
      "    (trimmers): ModuleList(\n",
      "      (0-2): 3 x SequenceTrimmer()\n",
      "    )\n",
      "    (input_embeds): ModuleList(\n",
      "      (0): Embed(\n",
      "        (input_bn): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (embed): Sequential(\n",
      "          (0): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): Linear(in_features=7, out_features=32, bias=True)\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "          (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (5): GELU(approximate='none')\n",
      "        )\n",
      "      )\n",
      "      (1): Embed(\n",
      "        (input_bn): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (embed): Sequential(\n",
      "          (0): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): Linear(in_features=5, out_features=32, bias=True)\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "          (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (5): GELU(approximate='none')\n",
      "        )\n",
      "      )\n",
      "      (2): Embed(\n",
      "        (input_bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (embed): Sequential(\n",
      "          (0): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): Linear(in_features=2, out_features=32, bias=True)\n",
      "          (2): GELU(approximate='none')\n",
      "          (3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "          (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (5): GELU(approximate='none')\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (part): ParticleTransformer(\n",
      "      (trimmer): SequenceTrimmer()\n",
      "      (embed): Identity()\n",
      "      (pair_embed): PairEmbed(\n",
      "        (embed): Sequential(\n",
      "          (0): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): Conv1d(4, 8, kernel_size=(1,), stride=(1,))\n",
      "          (2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): GELU(approximate='none')\n",
      "          (4): Conv1d(8, 8, kernel_size=(1,), stride=(1,))\n",
      "          (5): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): GELU(approximate='none')\n",
      "          (7): Conv1d(8, 4, kernel_size=(1,), stride=(1,))\n",
      "          (8): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (blocks): ModuleList(\n",
      "        (0-3): 4 x Block(\n",
      "          (pre_attn_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "          )\n",
      "          (post_attn_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (pre_fc_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (post_fc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (cls_blocks): ModuleList(\n",
      "        (0-1): 2 x Block(\n",
      "          (pre_attn_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "          )\n",
      "          (post_attn_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0, inplace=False)\n",
      "          (pre_fc_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (act_dropout): Dropout(p=0, inplace=False)\n",
      "          (post_fc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=32, out_features=2, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (train_acc): MulticlassAccuracy()\n",
      "  (val_acc): MulticlassAccuracy()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from ParticleTransformer import ParticleTransformerTaggerMultiGroups\n",
    "\n",
    "# Define an model instance\n",
    "# use the default parameters in the corresponding modules\n",
    "input_dims = (7, 5, 2)\n",
    "num_labels = 2\n",
    "\n",
    "model_part = ParticleTransformerTaggerMultiGroups(\n",
    "    input_dims,\n",
    "    num_classes=num_labels, \n",
    "    embed_dims=[32, 32],\n",
    "    pair_embed_dims=[8, 8],\n",
    "    num_heads=4,\n",
    "    num_layers=4,\n",
    ")\n",
    "\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "\n",
    "# Define the PyTorch Lightning module\n",
    "class ParTLightningModel(pl.LightningModule):\n",
    "    def __init__(self, model, start_lr=0.001):\n",
    "        super().__init__()\n",
    "        self.mod = model # model is an instance of ParticleNet, ParticleNeXt, or ParticleTransformer\n",
    "        self.start_lr = start_lr\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_labels)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_labels)\n",
    "\n",
    "    def forward(self, *x):\n",
    "        return self.mod(*x)\n",
    "\n",
    "    def process_model_input(self, x):\n",
    "        _, features, vectors = x\n",
    "        features = features.permute(0, 2, 1) # permute the features to (batch_size, num_features, num_tokens)\n",
    "        vectors = vectors.permute(0, 2, 1)\n",
    "        masks = torch.ones((features.size(0), 1, features.size(2)), dtype=torch.float32, device=features.device)\n",
    "\n",
    "        # form separate groups of tokens\n",
    "        feat_bjet, v_bjet, m_bjet = features[:,:,:2], vectors[:,:,:2], masks[:,:,:2]\n",
    "        feat_lep, v_lep, m_lep = features[:,:5,2:4], vectors[:,:,2:4], masks[:,:,2:4]\n",
    "        feat_met, v_met, m_met = features[:,:2,4:], vectors[:,:,4:], masks[:,:,4:]\n",
    "        return feat_bjet, v_bjet, m_bjet, feat_lep, v_lep, m_lep, feat_met, v_met, m_met\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch # x: a tuple of (points, features, vectors), y: label\n",
    "        logits = self(*self.process_model_input(x))\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.train_acc(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True)\n",
    "        self.log('lr', self.trainer.optimizers[0].param_groups[0]['lr'])\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch # x: a tuple of (points, features, vectors), y: label\n",
    "        logits = self(*self.process_model_input(x))\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.val_acc(logits, y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.start_lr)\n",
    "        \n",
    "        def lr_lambda(epoch):\n",
    "            if epoch < 0.7 * self.trainer.max_epochs:\n",
    "                return 1.0\n",
    "            else:\n",
    "                decay_factor = (epoch - 0.7 * self.trainer.max_epochs) / (0.3 * self.trainer.max_epochs)\n",
    "                return 0.01 ** decay_factor\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda) # LR scheduler定义为从70% epoch开始，指数衰减到1%\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "# 定义model的实例\n",
    "model_part_pl = ParTLightningModel(model_part)\n",
    "\n",
    "# 打印下这个模型进行检查\n",
    "print(model_part_pl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type                                 | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | mod       | ParticleTransformerTaggerMultiGroups | 82.7 K\n",
      "1 | train_acc | MulticlassAccuracy                   | 0     \n",
      "2 | val_acc   | MulticlassAccuracy                   | 0     \n",
      "-------------------------------------------------------------------\n",
      "82.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "82.7 K    Total params\n",
      "0.331     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2120aec473264387b52ce7e1cd9a3aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olympus/licq/utils/miniconda3/envs/weaver/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=71` in the `DataLoader` to improve performance.\n",
      "/home/olympus/licq/utils/miniconda3/envs/weaver/lib/python3.9/site-packages/torch/nn/functional.py:5038: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/home/olympus/licq/utils/miniconda3/envs/weaver/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=71` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46a920051274995ab6b23efad644b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olympus/licq/utils/miniconda3/envs/weaver/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "# Trainer with a logger\n",
    "trainer = pl.Trainer(max_epochs=50, logger=pl.loggers.TensorBoardLogger('tb_logs', name='particle_transformer'))\n",
    "\n",
    "# Fit the model\n",
    "trainer.fit(model_part_pl, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思考\n",
    "\n",
    "> 训练这个标准的 ParT 模型，其性能如何？在 Tensorboard 上观察训练过程的指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们使用这个接口再接入标准的 ParticleNet 文件，方便之后可能在一些任务中使用到。\n",
    "\n",
    "和上面的 ParT 相比，区别在于\n",
    "\n",
    " - 这里定义的 ParticleNet 模型，其初始化的参数有所不同。同样地，我们也使用了规模很小的 ParticleNet，可训练参数仅为 20.1k。\n",
    "\n",
    " - ParticleNet 模型对于每组 token 也接受三类input：`(points, features, mask)`。我们的新 Dataset 输出的 points 可以是为这里准备的。\n",
    "\n",
    " - ParticleNet 训练的起始learning rate相对较大。下面设置了 `start_lr=0.004`。\n",
    "\n",
    "观察 ParticleNet 的训练结果，与 ParT 和之前所有的 Transformer模型比，有哪些区别？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParticleNetLightningModel(\n",
      "  (mod): ParticleNetTaggerMultiGroups(\n",
      "    (convs): ModuleList(\n",
      "      (0): FeatureConv(\n",
      "        (conv): Sequential(\n",
      "          (0): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): Conv1d(7, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): FeatureConv(\n",
      "        (conv): Sequential(\n",
      "          (0): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): Conv1d(5, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (2): FeatureConv(\n",
      "        (conv): Sequential(\n",
      "          (0): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): Conv1d(2, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pn): ParticleNet(\n",
      "      (bn_fts): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (edge_convs): ModuleList(\n",
      "        (0): EdgeConvBlock(\n",
      "          (convs): ModuleList(\n",
      "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1-2): 2 x Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (bns): ModuleList(\n",
      "            (0-2): 3 x BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (acts): ModuleList(\n",
      "            (0-2): 3 x ReLU()\n",
      "          )\n",
      "          (sc_act): ReLU()\n",
      "        )\n",
      "        (1): EdgeConvBlock(\n",
      "          (convs): ModuleList(\n",
      "            (0-2): 3 x Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (bns): ModuleList(\n",
      "            (0-2): 3 x BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (acts): ModuleList(\n",
      "            (0-2): 3 x ReLU()\n",
      "          )\n",
      "          (sc): Conv1d(16, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (sc_bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (sc_act): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (fusion_block): Sequential(\n",
      "        (0): Conv1d(48, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (fc): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): Linear(in_features=64, out_features=2, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (train_acc): MulticlassAccuracy()\n",
      "  (val_acc): MulticlassAccuracy()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from ParticleNet import ParticleNetTaggerMultiGroups\n",
    "\n",
    "# Define an model instance\n",
    "# use the default parameters in the corresponding modules\n",
    "input_dims = (7, 5, 2)\n",
    "num_labels = 2\n",
    "\n",
    "model_pnet = ParticleNetTaggerMultiGroups(\n",
    "    input_dims,\n",
    "    num_classes=num_labels,\n",
    "    embed_dim=16,\n",
    "    conv_params=[(4, (16, 16, 16)), (4, (32, 32, 32))], # (kernel_size, (conv1_channels, conv2_channels, conv3_channels)). should have kernel_size <= num_tokens - 1\n",
    "    fc_params=[(64, 0.1)],\n",
    ")\n",
    "\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "\n",
    "# Define the PyTorch Lightning module\n",
    "class ParticleNetLightningModel(pl.LightningModule):\n",
    "    def __init__(self, model, start_lr=0.001):\n",
    "        super().__init__()\n",
    "        self.mod = model # model is an instance of ParticleNet, ParticleNeXt, or ParticleTransformer\n",
    "        self.start_lr = start_lr\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_labels)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_labels)\n",
    "\n",
    "    def forward(self, *x):\n",
    "        return self.mod(*x)\n",
    "\n",
    "    def process_model_input(self, x):\n",
    "        points, features, _ = x\n",
    "        points = points.permute(0, 2, 1) # permute the features to (batch_size, num_features, num_tokens)\n",
    "        features = features.permute(0, 2, 1)\n",
    "        masks = torch.ones((features.size(0), 1, features.size(2)), dtype=torch.float32, device=features.device)\n",
    "\n",
    "        # form separate groups of tokens\n",
    "        point_bjet, feat_bjet, m_bjet = points[:,:,:2], features[:,:,:2], masks[:,:,:2]\n",
    "        point_lep, feat_lep, m_lep = points[:,:,2:4], features[:,:5,2:4], masks[:,:,2:4]\n",
    "        point_met, feat_met, m_met = points[:,:,4:], features[:,:2,4:], masks[:,:,4:]\n",
    "        return point_bjet, feat_bjet, m_bjet, point_lep, feat_lep, m_lep, point_met, feat_met, m_met\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch # x: a tuple of (points, features, vectors), y: label\n",
    "        logits = self(*self.process_model_input(x))\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.train_acc(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True)\n",
    "        self.log('lr', self.trainer.optimizers[0].param_groups[0]['lr'])\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch # x: a tuple of (points, features, vectors), y: label\n",
    "        logits = self(*self.process_model_input(x))\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.val_acc(logits, y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.start_lr)\n",
    "        \n",
    "        def lr_lambda(epoch):\n",
    "            if epoch < 0.7 * self.trainer.max_epochs:\n",
    "                return 1.0\n",
    "            else:\n",
    "                decay_factor = (epoch - 0.7 * self.trainer.max_epochs) / (0.3 * self.trainer.max_epochs)\n",
    "                return 0.01 ** decay_factor\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda) # LR scheduler定义为从70% epoch开始，指数衰减到1%\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "# 定义model的实例\n",
    "model_pnet_pl = ParticleNetLightningModel(model_pnet, start_lr=0.004)\n",
    "\n",
    "# 打印下这个模型进行检查\n",
    "print(model_pnet_pl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type                         | Params\n",
      "-----------------------------------------------------------\n",
      "0 | mod       | ParticleNetTaggerMultiGroups | 20.1 K\n",
      "1 | train_acc | MulticlassAccuracy           | 0     \n",
      "2 | val_acc   | MulticlassAccuracy           | 0     \n",
      "-----------------------------------------------------------\n",
      "20.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.1 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d510a3bdfc384c839eb23a3a53746187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olympus/licq/utils/miniconda3/envs/weaver/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=71` in the `DataLoader` to improve performance.\n",
      "/home/olympus/licq/utils/miniconda3/envs/weaver/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=71` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abe6092d6964bca9fb6925b2a74bb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a34d0a168ed4022b111e4fc7b541320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af165b77e1f47f694de0dfeb7bd0079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6260301fde674f45bd1df776ccd13bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf01780df224e7d8130349934bfd628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742d0ba2032942dbb64852da8a7f155f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5808aa1d1214e7aad3c85c1d0e91896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867f92f8d5314e0e8c2a204a8f5c9750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c336281c5202474e88cb8e74b4b52769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3859f7ce8d4af9af829082f37476fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550837d5f23141578067a8e936344900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9761005e02924a8996796020ab5e73ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9de971138142d8b8c7f77c94433baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88be5c0dcff24ef797d9837090478244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab062874c67249f199ff388599d4dbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3ec2f095fa4973a8f4f5d8504a60fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519a82fe13df4f2da1a4f2aad8054a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd50b047d13475e88d056ec98b6c9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454ade4e8953475488d31f8814b89f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e0752a40b940e49dbeaf43666c5afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e690cd7d8b9f4aaca876ae036bcc103c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090951606cac474584859629734715fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b053e9229334de7ae34947869e0b12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c2c7df324f43f6b9d437b02ececf9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebb31761fe74d7ebe4d00be412b1d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f726f09088544f8985a255f76a5d804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfcc5c7a1104ee793c54081d41c6220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0591c5a1d5464066b3b0d54ed7c9c277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f648374626f4433f82b8d376eff776b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae66e679bec41c38a662359a57ba91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24913498e9e442c9ae8d57064ec24d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c481a1d617a040e8adf143f82c67f39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587e34418f164a4db4a161b7e3bbfe31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655817f48cd246d5ab79662185922103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5499242e3874f74a3d80fa0ddc02de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126cd1d2529244d7b23a533b8bda82d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fb193b7d254169b55c50fe443e5cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfdf0e865fbc4e3699cd90d4d87a3215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dd53d8c1cc422ba4c840cffb0bf566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7be3957c4f1429fbd93d5afa65566c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed5773383bc45ba8d1cd83a85afa350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba233f8c92894d288de92f5d534eaf14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62fcc33ccf40474582e5a3f6b081eeed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b530a63df44334886b1f7106e6b91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef830bfe95e4495a4fd8b0a17075ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c5b4a558ef47cbb717523c2df8fb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a6e9d3d03d43158ba00b2e88fcc038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2843b63cabd4ce29895a0b16f749295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b098be214248bcbe0dbace46657b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0e7c59b0b1418ea686ba53c0a5a6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81551366ed34f408b5a2da59a7b56b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    }
   ],
   "source": [
    "# Trainer with a logger\n",
    "trainer = pl.Trainer(max_epochs=50, logger=pl.loggers.TensorBoardLogger('tb_logs', name='particlenet'))\n",
    "\n",
    "# Fit the model\n",
    "trainer.fit(model_pnet_pl, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weaver-uproot5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
